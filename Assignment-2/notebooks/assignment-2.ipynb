{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habibarezq/ML-Assignments-25/blob/main/Assignment-2/notebooks/assignment-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "LyUSZbbVTzKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset,DataLoader ## to feed the data into the model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch"
      ],
      "metadata": {
        "id": "a2Liv3uRTyhO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preparation"
      ],
      "metadata": {
        "id": "bhnFQrNlxpVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Required Preprocessing and Transformations"
      ],
      "metadata": {
        "id": "1_1OEhoHiDpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomResizedCrop(224)\n",
        "])"
      ],
      "metadata": {
        "id": "slOSdLfziIfs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Training and test data"
      ],
      "metadata": {
        "id": "9x-CGy1cyYdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=datasets.MNIST(root=\"./data\", download=True, train=True, transform=transform)\n",
        "test_data=datasets.MNIST(root=\"./data\", download=True, train=False, transform=transform)\n"
      ],
      "metadata": {
        "id": "fJGs5eUbimR3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract data and labels"
      ],
      "metadata": {
        "id": "Kol3al2KydsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= dataset.data.float() /255.0\n",
        "y=dataset.targets\n",
        "\n",
        "print(f\"Full training data shape: {X.shape}\")\n",
        "print(f\"Full training labels shape: {y.shape}\")\n",
        "print(f\"Pixel value range: [{X.min():.2f}, {X.max():.2f}]\")"
      ],
      "metadata": {
        "id": "2LOFFPdbyiy4",
        "outputId": "3b535586-63b3-46f2-97fc-f6b23799b1cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full training data shape: torch.Size([60000, 28, 28])\n",
            "Full training labels shape: torch.Size([60000])\n",
            "Pixel value range: [0.00, 1.00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Filtering"
      ],
      "metadata": {
        "id": "GtpITb3SuL9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter first: only digits 0 and 1 from the whole dataset\n",
        "mask_train = (y == 0) | (y == 1)\n",
        "X_binary = X[mask_train]\n",
        "y_binary = y[mask_train]"
      ],
      "metadata": {
        "id": "KH3WaWzmuJjp"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Splitting\n",
        "\n"
      ],
      "metadata": {
        "id": "kCDSw381kfeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X_binary, y_binary, test_size=0.4, stratify=y_binary, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "1FBg8n_sbIsX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flatten Images"
      ],
      "metadata": {
        "id": "tjuW5k530FZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_flat = X_train.reshape(-1, 28*28)\n",
        "X_val_flat = X_val.reshape(-1, 28*28)\n",
        "X_test_flat = X_test.reshape(-1, 28*28)"
      ],
      "metadata": {
        "id": "E5HHcN1V0Hbr"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataloaders"
      ],
      "metadata": {
        "id": "drIvXsM4zvQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    TensorDataset(X_train_flat, y_train.float()),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    TensorDataset(X_val_flat, y_val.float()),\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(X_test_flat, y_test.float()),\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "uSHSUVv8z9y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logisitic Regression Implementation"
      ],
      "metadata": {
        "id": "-fHHuoG30OBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1+torch.exp(-x))\n",
        "\n",
        "def binary_cross_entropy(y_pred,y_true):\n",
        "  eps=1e-8 # avoid log(0)\n",
        "  return -torch.mean(y_true *  torch.log(y_pred + eps) + (1-y_true)*torch.log(1-y_pred))\n",
        "\n",
        "def compute_accuracy(y_pred,y_true):\n",
        "  pass\n",
        "\n",
        "def update_weights(X_batch,y_batch,W,b,alpha):\n",
        "      \"\"\"\n",
        "    Perform one gradient descent update for logistic regression.\n",
        "\n",
        "    Parameters:\n",
        "        X_batch (Tensor): Batch of input features, shape (batch_size, n_features)\n",
        "        y_batch (Tensor): Batch of true labels, shape (batch_size,)\n",
        "        W (Tensor): Weight matrix\n",
        "        b (Tensor): Bias term\n",
        "        alpha (float): Learning rate\n",
        "\n",
        "      \"\"\"\n",
        "      # Forward Pass\n",
        "      scores= X_batch @ W +b\n",
        "      y_pred=sigmoid(scores)\n",
        "\n",
        "      # Compute loss y_pred --> (batch_size,1) while y_batch has (batch,) --> use unsqueeze to a dimension\n",
        "      loss=binary_cross_entropy(y_pred,y_batch.unsqueeze(1))\n",
        "\n",
        "      #Compute gradients\n",
        "      error = y_pred - y_batch.unsqueeze(1)\n",
        "      dW=(X_batch.T @ error ) / X_batch.shape[0]\n",
        "      db=error.mean() # summation of error for batch divided by their number\n",
        "\n",
        "      #Update Weights\n",
        "      W -= alpha * dW\n",
        "      b -= alpha * db\n",
        "\n",
        "      return W,b"
      ],
      "metadata": {
        "id": "d3NK6TWFv95O"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initalize weights and bias\n"
      ],
      "metadata": {
        "id": "fC09o5oDwdfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features=28*28\n",
        "W=torch.zeros(n_features,1)\n",
        "b=torch.zeros(1)\n",
        "\n",
        "## Learning rate\n",
        "alpha=0.01\n",
        "epochs=100"
      ],
      "metadata": {
        "id": "m-65DynYwf5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "iunBkiAjw2x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses,val_losses=[]\n",
        "train_accuracies,val_accuracies=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        ""
      ],
      "metadata": {
        "id": "qI3fnUSJw5VY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}